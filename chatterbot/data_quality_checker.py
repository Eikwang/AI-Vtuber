"""
ChatterBot æ•°æ®è´¨é‡æ£€æŸ¥å’Œä¼˜åŒ–å·¥å…·
ç”¨äºåˆ†æè®­ç»ƒæ•°æ®çš„è´¨é‡ï¼Œå¹¶æä¾›æ”¹è¿›å»ºè®®
"""

import json
import os
from collections import Counter, defaultdict
import re

def analyze_conversation_quality(conversations):
    """åˆ†æå¯¹è¯è´¨é‡"""
    quality_report = {
        'total_pairs': len(conversations),
        'avg_question_length': 0,
        'avg_answer_length': 0,
        'short_questions': 0,
        'short_answers': 0,
        'long_questions': 0,
        'long_answers': 0,
        'duplicate_questions': 0,
        'similar_questions': 0,
        'question_types': Counter(),
        'answer_patterns': Counter(),
        'issues': []
    }
    
    if not conversations:
        return quality_report
    
    question_lengths = []
    answer_lengths = []
    questions = []
    answers = []
    
    # åˆ†ææ¯ä¸ªå¯¹è¯å¯¹
    for conv in conversations:
        if len(conv) >= 2:
            question = conv[0].strip()
            answer = conv[1].strip()
            
            questions.append(question)
            answers.append(answer)
            
            question_lengths.append(len(question))
            answer_lengths.append(len(answer))
            
            # æ£€æŸ¥è¿‡çŸ­çš„é—®é¢˜å’Œç­”æ¡ˆ
            if len(question) < 3:
                quality_report['short_questions'] += 1
            if len(answer) < 3:
                quality_report['short_answers'] += 1
            
            # æ£€æŸ¥è¿‡é•¿çš„é—®é¢˜å’Œç­”æ¡ˆ
            if len(question) > 100:
                quality_report['long_questions'] += 1
            if len(answer) > 200:
                quality_report['long_answers'] += 1
            
            # åˆ†æé—®é¢˜ç±»å‹
            if question.endswith('ï¼Ÿ') or question.endswith('?'):
                quality_report['question_types']['ç–‘é—®å¥'] += 1
            elif any(word in question for word in ['æ˜¯ä»€ä¹ˆ', 'ä»€ä¹ˆæ˜¯', 'æ€ä¹ˆ', 'å¦‚ä½•', 'ä¸ºä»€ä¹ˆ']):
                quality_report['question_types']['è¯¢é—®ç±»'] += 1
            elif any(word in question for word in ['ä½ å¥½', 'æ‚¨å¥½', 'è°¢è°¢', 'å†è§']):
                quality_report['question_types']['ç¤¼è²Œç”¨è¯­'] += 1
            else:
                quality_report['question_types']['å…¶ä»–'] += 1
            
            # åˆ†æç­”æ¡ˆæ¨¡å¼
            if len(answer) < 20:
                quality_report['answer_patterns']['ç®€çŸ­å›ç­”'] += 1
            elif len(answer) < 50:
                quality_report['answer_patterns']['ä¸­ç­‰å›ç­”'] += 1
            else:
                quality_report['answer_patterns']['è¯¦ç»†å›ç­”'] += 1
    
    # è®¡ç®—å¹³å‡é•¿åº¦
    if question_lengths:
        quality_report['avg_question_length'] = sum(question_lengths) / len(question_lengths)
    if answer_lengths:
        quality_report['avg_answer_length'] = sum(answer_lengths) / len(answer_lengths)
    
    # æ£€æŸ¥é‡å¤é—®é¢˜
    question_counts = Counter(questions)
    quality_report['duplicate_questions'] = sum(1 for count in question_counts.values() if count > 1)
    
    # æ£€æŸ¥ç›¸ä¼¼é—®é¢˜ï¼ˆç®€å•çš„ç›¸ä¼¼åº¦æ£€æŸ¥ï¼‰
    similar_pairs = 0
    for i, q1 in enumerate(questions):
        for j, q2 in enumerate(questions[i+1:], i+1):
            if calculate_simple_similarity(q1, q2) > 0.8:
                similar_pairs += 1
    quality_report['similar_questions'] = similar_pairs
    
    # ç”Ÿæˆé—®é¢˜æŠ¥å‘Š
    issues = []
    if quality_report['short_questions'] > quality_report['total_pairs'] * 0.1:
        issues.append(f"è¿‡å¤šçš„çŸ­é—®é¢˜: {quality_report['short_questions']} ä¸ª")
    if quality_report['short_answers'] > quality_report['total_pairs'] * 0.1:
        issues.append(f"è¿‡å¤šçš„çŸ­ç­”æ¡ˆ: {quality_report['short_answers']} ä¸ª")
    if quality_report['duplicate_questions'] > 0:
        issues.append(f"å­˜åœ¨é‡å¤é—®é¢˜: {quality_report['duplicate_questions']} ä¸ª")
    if quality_report['similar_questions'] > quality_report['total_pairs'] * 0.05:
        issues.append(f"ç›¸ä¼¼é—®é¢˜è¿‡å¤š: {quality_report['similar_questions']} å¯¹")
    
    quality_report['issues'] = issues
    
    return quality_report

def calculate_simple_similarity(text1, text2):
    """è®¡ç®—ä¸¤ä¸ªæ–‡æœ¬çš„ç®€å•ç›¸ä¼¼åº¦"""
    # ç§»é™¤æ ‡ç‚¹ç¬¦å·å¹¶è½¬ä¸ºå°å†™
    text1 = re.sub(r'[^\w\s]', '', text1.lower())
    text2 = re.sub(r'[^\w\s]', '', text2.lower())
    
    # è®¡ç®—è¯æ±‡é‡å åº¦
    words1 = set(text1.split())
    words2 = set(text2.split())
    
    if not words1 and not words2:
        return 1.0
    if not words1 or not words2:
        return 0.0
    
    intersection = len(words1.intersection(words2))
    union = len(words1.union(words2))
    
    return intersection / union if union > 0 else 0.0

def suggest_improvements(quality_report):
    """åŸºäºè´¨é‡æŠ¥å‘Šæä¾›æ”¹è¿›å»ºè®®"""
    suggestions = []
    
    if quality_report['short_questions'] > 0:
        suggestions.append(f"å»ºè®®æ‰©å±• {quality_report['short_questions']} ä¸ªè¿‡çŸ­çš„é—®é¢˜ï¼Œä½¿å…¶æ›´åŠ å…·ä½“å’Œæ˜ç¡®ã€‚")
    
    if quality_report['short_answers'] > 0:
        suggestions.append(f"å»ºè®®ä¸°å¯Œ {quality_report['short_answers']} ä¸ªè¿‡çŸ­çš„ç­”æ¡ˆï¼Œæä¾›æ›´è¯¦ç»†çš„ä¿¡æ¯ã€‚")
    
    if quality_report['duplicate_questions'] > 0:
        suggestions.append(f"å»ºè®®åˆå¹¶æˆ–åˆ é™¤ {quality_report['duplicate_questions']} ä¸ªé‡å¤çš„é—®é¢˜ã€‚")
    
    if quality_report['similar_questions'] > 0:
        suggestions.append(f"å»ºè®®æ£€æŸ¥ {quality_report['similar_questions']} å¯¹ç›¸ä¼¼çš„é—®é¢˜ï¼Œç¡®ä¿ç­”æ¡ˆä¸€è‡´æ€§ã€‚")
    
    # åˆ†æé—®é¢˜ç±»å‹åˆ†å¸ƒ
    question_types = quality_report['question_types']
    total_questions = sum(question_types.values())
    
    if total_questions > 0:
        inquiry_ratio = question_types.get('è¯¢é—®ç±»', 0) / total_questions
        greeting_ratio = question_types.get('ç¤¼è²Œç”¨è¯­', 0) / total_questions
        
        if inquiry_ratio < 0.3:
            suggestions.append("å»ºè®®å¢åŠ æ›´å¤šè¯¢é—®ç±»é—®é¢˜ï¼ˆå¦‚'æ˜¯ä»€ä¹ˆ'ã€'æ€ä¹ˆ'ç­‰ï¼‰ä»¥æé«˜å®ç”¨æ€§ã€‚")
        
        if greeting_ratio < 0.1:
            suggestions.append("å»ºè®®å¢åŠ åŸºæœ¬çš„ç¤¼è²Œç”¨è¯­é—®ç­”ä»¥æ”¹å–„ç”¨æˆ·ä½“éªŒã€‚")
    
    # åˆ†æç­”æ¡ˆé•¿åº¦åˆ†å¸ƒ
    answer_patterns = quality_report['answer_patterns']
    total_answers = sum(answer_patterns.values())
    
    if total_answers > 0:
        short_ratio = answer_patterns.get('ç®€çŸ­å›ç­”', 0) / total_answers
        detailed_ratio = answer_patterns.get('è¯¦ç»†å›ç­”', 0) / total_answers
        
        if short_ratio > 0.7:
            suggestions.append("å»ºè®®å¢åŠ æ›´å¤šè¯¦ç»†çš„å›ç­”ä»¥æä¾›æ›´æœ‰ä»·å€¼çš„ä¿¡æ¯ã€‚")
        elif detailed_ratio > 0.8:
            suggestions.append("å¯ä»¥è€ƒè™‘ç®€åŒ–ä¸€äº›è¿‡äºè¯¦ç»†çš„å›ç­”ï¼Œæé«˜å“åº”æ•ˆç‡ã€‚")
    
    return suggestions

def analyze_corpus_file(file_path):
    """åˆ†æå•ä¸ªè¯­æ–™æ–‡ä»¶"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        if 'conversations' not in data:
            return None, "æ–‡ä»¶æ ¼å¼é”™è¯¯ï¼šç¼ºå°‘ 'conversations' å­—æ®µ"
        
        conversations = data['conversations']
        quality_report = analyze_conversation_quality(conversations)
        suggestions = suggest_improvements(quality_report)
        
        return {
            'file_path': file_path,
            'quality_report': quality_report,
            'suggestions': suggestions
        }, None
        
    except Exception as e:
        return None, f"åˆ†ææ–‡ä»¶æ—¶å‡ºé”™: {e}"

def generate_quality_report(data_dir="./data"):
    """ç”Ÿæˆå®Œæ•´çš„æ•°æ®è´¨é‡æŠ¥å‘Š"""
    print("=== ChatterBot æ•°æ®è´¨é‡åˆ†ææŠ¥å‘Š ===\n")
    
    if not os.path.exists(data_dir):
        print(f"é”™è¯¯: ç›®å½• {data_dir} ä¸å­˜åœ¨")
        return
    
    # æ‰¾åˆ°æ‰€æœ‰JSONæ–‡ä»¶
    json_files = []
    for root, dirs, files in os.walk(data_dir):
        for f in files:
            if f.endswith('.json'):
                json_files.append(os.path.join(root, f))
    
    if not json_files:
        print(f"åœ¨ç›®å½• {data_dir} ä¸­æœªæ‰¾åˆ°JSONæ–‡ä»¶")
        return
    
    print(f"æ‰¾åˆ° {len(json_files)} ä¸ªJSONæ–‡ä»¶ï¼Œå¼€å§‹åˆ†æ...\n")
    
    total_quality_report = {
        'total_files': len(json_files),
        'valid_files': 0,
        'total_conversations': 0,
        'total_issues': 0,
        'file_reports': []
    }
    
    # åˆ†ææ¯ä¸ªæ–‡ä»¶
    for json_file in json_files:
        print(f"åˆ†ææ–‡ä»¶: {os.path.basename(json_file)}")
        print("-" * 50)
        
        result, error = analyze_corpus_file(json_file)
        
        if error:
            print(f"âœ— é”™è¯¯: {error}\n")
            continue
        
        total_quality_report['valid_files'] += 1
        total_quality_report['total_conversations'] += result['quality_report']['total_pairs']
        total_quality_report['total_issues'] += len(result['quality_report']['issues'])
        total_quality_report['file_reports'].append(result)
        
        # æ˜¾ç¤ºæ–‡ä»¶åˆ†æç»“æœ
        quality = result['quality_report']
        print(f"âœ“ å¯¹è¯å¯¹æ•°é‡: {quality['total_pairs']}")
        print(f"âœ“ å¹³å‡é—®é¢˜é•¿åº¦: {quality['avg_question_length']:.1f} å­—ç¬¦")
        print(f"âœ“ å¹³å‡ç­”æ¡ˆé•¿åº¦: {quality['avg_answer_length']:.1f} å­—ç¬¦")
        
        # æ˜¾ç¤ºé—®é¢˜ç±»å‹åˆ†å¸ƒ
        if quality['question_types']:
            print("âœ“ é—®é¢˜ç±»å‹åˆ†å¸ƒ:")
            for qtype, count in quality['question_types'].most_common():
                percentage = count / quality['total_pairs'] * 100
                print(f"   - {qtype}: {count} ä¸ª ({percentage:.1f}%)")
        
        # æ˜¾ç¤ºè´¨é‡é—®é¢˜
        if quality['issues']:
            print("âš  å‘ç°çš„é—®é¢˜:")
            for issue in quality['issues']:
                print(f"   - {issue}")
        else:
            print("âœ“ æœªå‘ç°æ˜æ˜¾è´¨é‡é—®é¢˜")
        
        # æ˜¾ç¤ºæ”¹è¿›å»ºè®®
        if result['suggestions']:
            print("ğŸ’¡ æ”¹è¿›å»ºè®®:")
            for suggestion in result['suggestions']:
                print(f"   - {suggestion}")
        
        print()
    
    # ç”Ÿæˆæ€»ä½“æŠ¥å‘Š
    print("=" * 60)
    print("æ€»ä½“è´¨é‡æŠ¥å‘Š")
    print("=" * 60)
    print(f"âœ“ åˆ†æäº† {total_quality_report['valid_files']}/{total_quality_report['total_files']} ä¸ªæœ‰æ•ˆæ–‡ä»¶")
    print(f"âœ“ æ€»å¯¹è¯å¯¹æ•°: {total_quality_report['total_conversations']}")
    print(f"âš  æ€»è´¨é‡é—®é¢˜æ•°: {total_quality_report['total_issues']}")
    
    if total_quality_report['total_conversations'] > 0:
        avg_quality_score = max(0, 100 - (total_quality_report['total_issues'] / total_quality_report['total_conversations'] * 100))
        print(f"ğŸ“Š æ•´ä½“è´¨é‡è¯„åˆ†: {avg_quality_score:.1f}/100")
        
        if avg_quality_score >= 80:
            print("âœ… æ•°æ®è´¨é‡è‰¯å¥½ï¼Œå¯ä»¥å¼€å§‹è®­ç»ƒ")
        elif avg_quality_score >= 60:
            print("âš¡ æ•°æ®è´¨é‡ä¸€èˆ¬ï¼Œå»ºè®®å…ˆè¿›è¡Œä¸€äº›ä¼˜åŒ–")
        else:
            print("âŒ æ•°æ®è´¨é‡è¾ƒå·®ï¼Œå¼ºçƒˆå»ºè®®å…ˆä¼˜åŒ–æ•°æ®å†è®­ç»ƒ")
    
    # ç»™å‡ºæ€»ä½“å»ºè®®
    print("\nğŸ¯ æ€»ä½“ä¼˜åŒ–å»ºè®®:")
    if total_quality_report['total_conversations'] < 100:
        print("   - å¢åŠ æ›´å¤šçš„è®­ç»ƒæ•°æ®ä»¥æé«˜æ¨¡å‹æ€§èƒ½")
    if total_quality_report['total_issues'] > total_quality_report['total_conversations'] * 0.1:
        print("   - ä¼˜å…ˆè§£å†³æ•°æ®è´¨é‡é—®é¢˜")
    print("   - ç¡®ä¿é—®ç­”å¯¹çš„å¤šæ ·æ€§å’Œç›¸å…³æ€§")
    print("   - å®šæœŸæ›´æ–°å’Œç»´æŠ¤è®­ç»ƒæ•°æ®")

def find_duplicate_questions(data_dir="./data"):
    """æŸ¥æ‰¾é‡å¤çš„é—®é¢˜"""
    all_questions = defaultdict(list)
    
    for root, dirs, files in os.walk(data_dir):
        for f in files:
            if f.endswith('.json'):
                file_path = os.path.join(root, f)
                try:
                    with open(file_path, 'r', encoding='utf-8') as file:
                        data = json.load(file)
                        if 'conversations' in data:
                            for i, conv in enumerate(data['conversations']):
                                if len(conv) >= 2:
                                    question = conv[0].strip()
                                    all_questions[question].append({
                                        'file': os.path.basename(file_path),
                                        'index': i,
                                        'answer': conv[1].strip()
                                    })
                except Exception as e:
                    print(f"è¯»å–æ–‡ä»¶ {file_path} æ—¶å‡ºé”™: {e}")
    
    # æ‰¾å‡ºé‡å¤çš„é—®é¢˜
    duplicates = {q: occurrences for q, occurrences in all_questions.items() if len(occurrences) > 1}
    
    if duplicates:
        print("=== é‡å¤é—®é¢˜æŠ¥å‘Š ===")
        print(f"å‘ç° {len(duplicates)} ä¸ªé‡å¤çš„é—®é¢˜:\n")
        
        for question, occurrences in duplicates.items():
            print(f"é—®é¢˜: {question}")
            print(f"å‡ºç°æ¬¡æ•°: {len(occurrences)}")
            for occ in occurrences:
                print(f"  - æ–‡ä»¶: {occ['file']}, ä½ç½®: {occ['index']}, ç­”æ¡ˆ: {occ['answer'][:50]}...")
            print()
    else:
        print("âœ“ æœªå‘ç°é‡å¤çš„é—®é¢˜")

if __name__ == "__main__":
    # ç”Ÿæˆè´¨é‡æŠ¥å‘Š
    generate_quality_report()
    
    print("\n" + "=" * 60)
    
    # æŸ¥æ‰¾é‡å¤é—®é¢˜
    find_duplicate_questions()